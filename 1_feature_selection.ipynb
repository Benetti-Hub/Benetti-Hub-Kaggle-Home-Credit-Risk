{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Benetti-Hub/Benetti-Hub-Kaggle-Home-Credit-Risk/blob/main/1_feature_selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0dQxIY0omu6"
      },
      "source": [
        "# Feature Selection with Adversarial Validation and Univariate ROC-AUC\n",
        "\n",
        "One of the primary challenges in this competition was identifying features that remained stable over time. To address this, I employed adversarial validation to pinpoint the most crucial features. This method hinges on the principle that the distributions of the training and test sets should be similar. When these distributions align, the features significant for the training set are likely to be equally important for the test set.\n",
        "\n",
        "In addition, I utilized the ROC-AUC score to further refine feature selection. The ROC-AUC score is a metric that evaluates a model's ability to distinguish between classes. Here, I used it to assess a feature's capability to differentiate between the training and test sets.\n",
        "\n",
        "The feature selection methods employed here aim to maximize the ROC-AUC while keeping computational constraints to a minimum. Many features are correlated or redundant, but LightGBM is capable of ignoring this redundancy. In a production environment, a more rigorous feature selection process, such as step-forward feature selection, SHAP values, or L1 regularization, would be applied to ensure the optimal set of features is utilized."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0bJwJy5QOvB2"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install --upgrade polars\n",
        "!pip install --upgrade pandas\n",
        "!pip install lightgbm\n",
        "!pip install pyarrow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-07T10:52:42.242112Z",
          "iopub.status.busy": "2024-04-07T10:52:42.241877Z",
          "iopub.status.idle": "2024-04-07T10:52:47.481358Z",
          "shell.execute_reply": "2024-04-07T10:52:47.480522Z",
          "shell.execute_reply.started": "2024-04-07T10:52:42.24209Z"
        },
        "id": "Fd_Ro9dPOZJ2",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "from multiprocessing import Pool\n",
        "\n",
        "import lightgbm as lgb\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ai5d5ZZmKw_R",
        "outputId": "c26d3087-6263-42a3-fda5-e84a02e893bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "# Setup the directory for the notebook:s\n",
        "DRIVE_PATH = \"/content/drive/MyDrive/Projects/KaggleDefaults\"\n",
        "os.makedirs(DRIVE_PATH, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dUsnuph3RYuU"
      },
      "outputs": [],
      "source": [
        "def cast_cat(data: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Cast any object column to category\"\"\"\n",
        "    cat_cols = data.select_dtypes(include=\"object\").columns\n",
        "    data[cat_cols] = data[cat_cols].astype(\"category\")\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "class TimeSeriesSplitter:\n",
        "    \"\"\"Scikit-learn style TimeSeriesSplitter to batch custers\n",
        "    of time series data together for cross-validation.\"\"\"\n",
        "\n",
        "    def __init__(self, n_splits=5):\n",
        "        self.n_splits = n_splits\n",
        "\n",
        "    def split(self, X, y, group):\n",
        "        groups = np.array_split(group.unique(), self.n_splits)\n",
        "        for bounds in groups:\n",
        "            mask = group.isin(bounds)\n",
        "\n",
        "            yield X[mask].index, X[~mask].index\n",
        "\n",
        "    def get_n_splits(self):\n",
        "        return self.n_splits\n",
        "\n",
        "\n",
        "def eval_performance(feat: list[str] | str) -> list[float]:\n",
        "\n",
        "    params = {\n",
        "        \"max_depth\": 3,\n",
        "        \"n_estimators\": 10,\n",
        "        \"verbose\": -1,\n",
        "        \"random_state\": 42,\n",
        "        \"n_jobs\": 1,\n",
        "    }\n",
        "    uni_model = lgb.LGBMClassifier(**params)\n",
        "    adv_model = lgb.LGBMClassifier(**params)\n",
        "\n",
        "    data = train_data[[feat]]\n",
        "    target_adv = np.zeros(data.shape[0])\n",
        "\n",
        "    cv = TimeSeriesSplitter(n_splits=5)\n",
        "    adv_scores = np.zeros(cv.get_n_splits())\n",
        "    uni_scores = np.zeros(cv.get_n_splits())\n",
        "    for i, (train_idx, valid_idx) in enumerate(\n",
        "        cv.split(data, target_adv, train_data[\"WEEK_NUM\"])\n",
        "    ):\n",
        "        # Adversarial validation\n",
        "        target_adv[valid_idx] = 1\n",
        "        X_train, X_valid, y_adv_train, y_adv_valid = train_test_split(\n",
        "            data, target_adv, test_size=0.33, random_state=42, shuffle=True\n",
        "        )\n",
        "        adv_model.fit(X_train, y_adv_train)\n",
        "        adv_scores[i] = roc_auc_score(\n",
        "            y_adv_valid, adv_model.predict_proba(X_valid)[:, 1]\n",
        "        )\n",
        "        target_adv[valid_idx] = 0\n",
        "\n",
        "        # Univariate\n",
        "        X_train, X_valid = data.iloc[train_idx], data.iloc[valid_idx]\n",
        "        y_train, y_valid = (\n",
        "            train_data[\"target\"].iloc[train_idx],\n",
        "            train_data[\"target\"].iloc[valid_idx],\n",
        "        )\n",
        "        uni_model.fit(X_train, y_train)\n",
        "        uni_scores[i] = roc_auc_score(y_valid, uni_model.predict_proba(X_valid)[:, 1])\n",
        "\n",
        "    return (*adv_scores, *uni_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "__pB-XgxqZzh"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_parquet(f\"{DRIVE_PATH}/train_data_pandas.parquet\").pipe(cast_cat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oozlDJqfpH0",
        "outputId": "d77e07b5-1323-4768-f604-86e340edd9ef"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 4507/4508 [20:32<00:00,  3.66it/s]\n"
          ]
        }
      ],
      "source": [
        "file_path = f\"{DRIVE_PATH}/cat_best.parquet\"\n",
        "if os.path.isfile(file_path):\n",
        "    univ_results = pd.read_parquet(file_path)\n",
        "else:\n",
        "    feat_cols = sorted(set(train_data.columns) - {\"case_id\", \"WEEK_NUM\", \"target\"})\n",
        "    scores = dict(\n",
        "        zip(\n",
        "            feat_cols,\n",
        "            tqdm(Pool().imap(eval_performance, feat_cols), total=len(feat_cols)),\n",
        "        )\n",
        "    )\n",
        "    adv_cols = [f\"adv_{c}\" for c in range(5)]\n",
        "    uni_cols = [f\"uni_{c}\" for c in range(5)]\n",
        "    univ_results = (\n",
        "        pd.DataFrame.from_dict(scores, orient=\"index\", columns=[*adv_cols, *uni_cols])\n",
        "        .reset_index()\n",
        "        .assign(\n",
        "            **{\n",
        "                \"adv_avg\": lambda x: np.mean(x[adv_cols], axis=1),\n",
        "                \"uni_avg\": lambda x: np.mean(x[uni_cols], axis=1),\n",
        "                \"uni_max\": lambda x: np.max(x[uni_cols], axis=1),\n",
        "                \"uni_min\": lambda x: np.min(x[uni_cols], axis=1),\n",
        "                \"feature\": lambda x: x[\"index\"].str.split(\"_\").str[-1],\n",
        "            }\n",
        "        )\n",
        "        .sort_values(by=\"uni_min\", ascending=False)\n",
        "    )\n",
        "    univ_results.to_parquet(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Qb3o9WuIg6dE"
      },
      "outputs": [],
      "source": [
        "univ_reduced = univ_results.sort_values(by=\"uni_avg\", ascending=False).query(\n",
        "    \"uni_avg > 0.51 and adv_avg < 0.8\"\n",
        ")\n",
        "\n",
        "with open(f\"{DRIVE_PATH}/to_keep.pkl\", \"wb\") as f:\n",
        "    pickle.dump(univ_reduced[\"index\"].to_list(), f)\n",
        "\n",
        "\n",
        "to_drop = sorted(set(univ_results[\"index\"]) - set(univ_reduced[\"index\"].to_list()))\n",
        "with open(f\"{DRIVE_PATH}/to_drop.pkl\", \"wb\") as f:\n",
        "    pickle.dump(to_drop, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OsA1MZM5Ku05"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "databundleVersionId": 7921029,
          "sourceId": 50160,
          "sourceType": "competition"
        },
        {
          "datasetId": 4617924,
          "sourceId": 7976338,
          "sourceType": "datasetVersion"
        }
      ],
      "isGpuEnabled": true,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
